FROM python:3.11-slim

# CPU-only Dockerfile for VisionText
# - Uses a slim Python base image (no CUDA libraries)
# - Installs CPU PyTorch wheels (via official PyTorch CPU index) and then
#   installs the rest of Python requirements from requirements.txt

RUN apt-get update && apt-get install -y \
    tesseract-ocr \
    libgl1 \
    libglib2.0-0 \
    libsm6 \
    libxrender1 \
    libxext6 \
    ffmpeg \
    git \
    build-essential \
    cmake \
    wget \
    libsndfile1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

ENV PIP_NO_CACHE_DIR=0
ENV PIP_DEFAULT_TIMEOUT=100
ENV HF_HOME=/app/models/huggingface
ENV TRANSFORMERS_CACHE=/app/models/huggingface/transformers
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

RUN mkdir -p /app/models/huggingface

COPY requirements.txt .

# Install CPU PyTorch wheels first (official CPU index). If this index is
# unavailable for a particular platform, the fallback pip install will try
# the default index which may provide a CPU wheel.
RUN --mount=type=cache,target=/root/.cache/pip \
    --mount=type=cache,target=/root/.cache/pip/http \
    pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu \
        "torch" "torchvision" "torchaudio" || \
    pip install --no-cache-dir "torch" "torchvision" "torchaudio" || true

# Install the remaining Python requirements
RUN --mount=type=cache,target=/root/.cache/pip \
    --mount=type=cache,target=/root/.cache/pip/http \
    pip install --cache-dir /root/.cache/pip -r requirements.txt

# Copy app files FIRST before preload to ensure modules are available
COPY app ./app
COPY static ./static
COPY docker/preload_models.py /preload_models.py
COPY docker/healthcheck.py /healthcheck.py

# Preload models (optional)
RUN python /preload_models.py || true

# Ensure app is importable
RUN python -c "from app.main import app; print('âœ“ app.main imported successfully')" || true

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
